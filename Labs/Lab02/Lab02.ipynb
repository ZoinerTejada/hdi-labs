{"nbformat_minor": 2, "cells": [{"source": "# Lab 2 - Data Warehouse / Interactive Pattern - Interactive Querying with Spark, LLAP and Power BI", "cell_type": "markdown", "metadata": {}}, {"source": "AdventureWorks would like to create some visualizations of their data to better understand their customers. They are interested in using the powerful visualization capabilities of Power BI and its ability to allow them to share those visualizations, but aren't sure how they can pull in the data to create the dashboards.\n\nThey have provided all the weblogs and user tables that you can use to quickly explore the data, and have the product information available in flat files. You will prepare the data to be used in Power BI, explore the data using Spark SQL and Jupyter's built-in visualizations, as well as Matplotlib for more advanced control. Finally, you will import the data into Power BI to create interactive dashboards and reports.", "cell_type": "markdown", "metadata": {}}, {"source": "## Explore the weblog and user data", "cell_type": "markdown", "metadata": {}}, {"source": "Let's take a look at the data and come up with some interesting visualizations based on what we find.", "cell_type": "markdown", "metadata": {}}, {"source": "First, let's import the Python modules and functions we will use in this notebook.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "from pyspark import SparkContext\nfrom pyspark.sql import *\nfrom pyspark.sql.types import *", "outputs": [], "metadata": {"collapsed": false}}, {"source": "User actions are captured in the weblogs as they navigate through the site. Let's find out which actions are captured, and how many of each action users performed. We'll sore from the highest count to the lowest.\n\nUse the `%%sql` magic parameters to save the query results to a [Pandas](http://pandas.pydata.org/) DataFrame in the `%%local` context. This way, we can use the output in our Matplotlib charts.\n\n> To learn more about the `%%sql` magic, and other magics available with the PySpark kernel, see [Kernels available on Jupyter notebooks with Spark HDInsight clusters](https://docs.microsoft.com/azure/hdinsight/hdinsight-apache-spark-jupyter-notebook-kernels#parameters-supported-with-the-sql-magic).", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# TODO: use the %%sql magic output parameter to save the query result to local DataFrame named query1\n%%sql #Complete this line#\nselect Action, Count(weblogs.*) as Ct from weblogs\ninner join users on weblogs.userid = users.id\ngroup by #Complete this line#\norder by Ct desc", "outputs": [], "metadata": {"scrolled": true, "collapsed": false}}, {"source": "After executing the above query, use the built-in tabs to change the display Type from a Table to other visualizations, such as Pie and Bar charts.\n\nNow, let's alter the query to show the same actions and their counts by gender. This will help us spot differences in how men and women use the site, and which group is ultimately most likely to make a purchase.\n\nAs we did with the previous query, use the `%%sql` magic parameters to save the query results to a new Pandas DataFrame.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# TODO: use the %%sql magic output parameter to save the query result to local DataFrame named query2\n%%sql #Complete this line#\nselect Action, Gender, Count(weblogs.*) as Ct from weblogs\ninner join users on weblogs.userid = users.id\ngroup by #Complete this line#\norder by Ct desc", "outputs": [], "metadata": {"collapsed": false}}, {"source": "As you did previously, use the built-in Pie chart visualization to view the breakdown of Action percentages. Use the Bar chart to display the total count of each action. Now change the chart's settings to display the total count of all actions by gender. One limitation of this built-in chart that you may notice, is that you cannot use it to compare the total count of each action by gender. Let's configure and use Matplotlib to help us with this visualization.", "cell_type": "markdown", "metadata": {}}, {"source": "First, we need to switch to the local context and import the required libraries.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%local\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline", "outputs": [], "metadata": {"collapsed": true}}, {"source": "We need to make sure the Matplotlib commands are run in the local context. To test things out, let's recreate the pie chart showing the Action percentages, using Matplotlib.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# TODO: switch to the local context\n\nlabels = query1['Action']\ncounts = query1#Complete this line#\ncolors = ['turquoise', 'seagreen', 'mediumslateblue']\nplt.pie(counts, labels=labels, autopct='%1.1f%%', colors=#Complete this line#\nplt.axis('equal')\nplt.show()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "To compare actions made by gender, we need to split up the local Pandas [DataFrames](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame) into smaller DataFrames that we can use for our charts.\n\n> A quick reference guide you can use to get up and running quickly with Pandas is the [10 minutes to pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html) page on their site.\n\nLooking at the pie chart above, we can see that the vast majority of the site's logged data is from people browsing the site. We need to break down the DataFrames further into two groups of actions so we can more easily drill down into the details of these groups: Purchasing, and Browsing.\n\nCreate the following DataFrames from the second Pandas DataFrame you created using the `%%sql` magic above:\n\n1. men: Gender = Male, sorted by Action in descending order\n2. women: Gender = Female, sorted by Action in descending order\n3. men_purchasing: Gender = Male, includes the following actions: Add to Cart and Purchased\n4. women_purchasing: Gender = Female, includes the following actions: Add to Cart and Purchased\n5. men_browsing: Gender = Male, with the Browse action\n6. women_browsing: Gender = Female, with the Browse action\n7. labels: All of the actions in either the men_purchasing DataFrame, or the women_purchasing DataFrame\n8. men_purchasing_counts: The Ct values from the men_purchasing DataFrame\n9. women_purchasing_counts: The Ct values from the women_purchasing DataFrame\n10. men_browsing_counts: The Ct values from the men_browsing DataFrame\n11. women_browsing_counts: The Ct values from the women_browsing DataFrame", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%local\n\n# TODO: Complete the Pandas DataFrames below, referencing the list above\n\nmen = query2[query2['Gender'] == 'Male'].sort_values(by=#Complete this line#\nwomen = query2[query2['Gender'] == 'Female'].sort_values(by=#Complete this line#\nmen_purchasing = men[men['Action'].isin([#Complete this line#\nwomen_purchasing = women[women['Action'].isin([#Complete this line#\nmen_browsing = men[men['Action'] == 'Browsed']\nwomen_browsing = women[women['Action'] == 'Browsed']\nlabels = men_purchasing['Action']\n\nmen_purchasing_counts = men_purchasing[#Complete this line#\nwomen_purchasing_counts = women_purchasing[#Complete this line#\nmen_browsing_counts = men_browsing[#Complete this line#\nwomen_browsing_counts = women_browsing[#Complete this line#", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Print the `men`, `women`, and `labels` DataFrames to take a quick look at the data we're working with.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%local\n\n# TODO: Print the following DataFrames: men, women, labels\n\nprint(#Complete this line#\nprint(#Complete this line#\nprint(#Complete this line#", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Now that we have our DataFrames defined, let's create and configure a Matplotlib stacked Bar chart with women's values on top and men's values underneath. The values should come from the men's and women's purchasing counts DataFrames so we can compare how many women ultimately purchase items from the AdventureWorks store vs. men.\n\nColor code the bars as you see fit, and make certain to add a legend indicating either Men or Women.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%local\n\nN = 2\nind = np.arange(N)    # the x locations for the groups\nwidth = 0.35       # the width of the bars: can also be len(x) sequence\n\np1 = plt.bar(ind, men_purchasing_counts, width, color='#d62728')\n# TODO: Set the bottom of the bar to men_purchasing_counts\np2 = plt.bar(ind, women_purchasing_counts, width, #Complete this line#\n\n# TODO: Set the ylabel to \"Counts\"\nplt.#Complete this line#\nplt.title('Purchasing actions by gender')\nplt.xticks(ind, labels)\nplt.legend((p1[0], p2[0]), ('Men', 'Women'))\n#plt.xkcd(scale=1, length=100, randomness=2)\nplt.show()", "outputs": [], "metadata": {"scrolled": true, "collapsed": false}}, {"source": "The chart shows us that women, by a vast majority, conduct purchasing actions on the website, compared to men. Many more in both groups add items to the cart than actually complete the purchase.\n\nLet us compare browsing statistics between the genders. This should also be a bar chart, but display men's values next to the women's.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%local\n\nfig, ax = plt.subplots()\nlabels = men_browsing['Action']\nind = np.arange(1)\np1 = ax.bar(ind, men_browsing_counts, width, color='#d62728')\np2 = ax.bar(ind + width, women_browsing_counts, width)\n\nax.set_ylabel('Counts')\nax.set_title('Browsing counts by gender')\nax.set_xticks(ind + width / 2)\nax.set_xticklabels(labels)\nax.legend((p1[0], p2[0]), ('Men', 'Women'))\n\nplt.show()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "As you can see from this chart, though the women greatly outperformed the men in purchases, men tend to browse through AdventureWork's product category by more than double. They just appear to not be converting to buyers for some reason. Perhaps this is something the marketing team needs to look into? Or maybe the website's content team.\n\nOne thing that makes this chart more difficult to comprehend, is that the counts include an exponential label (1e7), since the values are in the tens of millions, instead showing 0 - 7 as the count values on the y axis.\n\nLet's make this easier to read by displaying the actual count values above each bar. To do this, modify the bar chart code to include a function that accepts a rectangle collection, and sets the text based on the height value of each. Pass the men and women bars to this function.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%local\n\nfig, ax = plt.subplots()\nlabels = men_browsing['Action']\nind = np.arange(1)\np1 = ax.bar(ind, men_browsing_counts, width, color='#d62728')\np2 = ax.bar(ind + width, women_browsing_counts, width)\n\nax.set_ylabel('Counts')\nax.set_title('Browsing counts by gender')\nax.set_xticks(ind + width / 2)\nax.set_xticklabels(labels)\nax.legend((p1[0], p2[0]), ('Men', 'Women'))\n\ndef autolabel(rects):\n    \"\"\"\n    Attach a text label above each bar displaying its height\n    \"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n                '%d' % int(height),\n                ha='center', va='bottom')\n\n# TODO: Pass both bars to the autolabel function\nautolabel(#Complete this line#\nautolabel(#Complete this line#\nplt.show()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Explore the product data", "cell_type": "markdown", "metadata": {}}, {"source": "Now we need to load and parse the product data from Azure Storage so we can work with it.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "products_schema = StructType([\n        StructField('ProductId',IntegerType(),False), \n        StructField('ProductName', StringType()), \n        StructField('Price', FloatType()), \n        StructField('CategoryId', StringType()), \n        StructField('Ignore1', StringType()), \n        StructField('Ignore2', StringType()), \n        StructField('Ignore3', StringType()), \n        StructField('Category', StringType()), \n        StructField('Department', StringType())\n    ])\n\nproducts_DF = spark.read.csv(\"/retaildata/rawdata/ProductFile/part{*}\", \n                    schema=products_schema,\n                    header=False)\n\nproducts_DF_with_price = products_DF.select(\"ProductId\", \"ProductName\", \"Price\", \"CategoryId\", \"Category\", \"Department\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Save the product data to a Hive table named Products.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "products_DF_with_price.write.mode(\"overwrite\").saveAsTable(\"Products\")", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Verify that the table was successfully created.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nshow tables", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Only the tables that have false under the isTemporary column are Hive tables that are stored in the metastore and can be accessed from Power BI. We will be using the products, users, and weblogs tables.\n\nLet's take a look at some of the data in the new Products table.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# TODO: select the top 10 rows from the new products table \n%%sql\nselect * #Complete this line#", "outputs": [], "metadata": {"collapsed": false}}, {"source": "It's important to know the top products sold, and which categories they are part of. But an interesting data point for marketing may be what the average age is of the purchasers of those products.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nselect ProductName, Category, Avg(Age), Count(weblogs.*) as Ct from products inner join weblogs\non weblogs.productid = products.productid inner join users on weblogs.userid = users.id\nwhere weblogs.Action = 'Purchased'\ngroup by --Complete this line\norder by ct desc\nlimit 5", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Now that we have a good sense of the data, we can start building the charts in Power BI. We'll work on that next.", "cell_type": "markdown", "metadata": {}}, {"source": "## Reference tables using DirectQuery in Power BI", "cell_type": "markdown", "metadata": {}}, {"source": "Power BI will allow us to quickly create these charts, now that we've explored the data for a bit.", "cell_type": "markdown", "metadata": {}}, {"source": "You will need to download the [Power BI Desktop](https://powerbi.microsoft.com/desktop/) software to complete these steps.\n\n1. From Power BI Desktop, select dropdown under **Get Data**, then **More...**. In the Get Data window, select Azure, then Azure HDInsight Spark (Beta).\n\n![Get Data](https://raw.githubusercontent.com/ZoinerTejada/hdi-labs/master/Labs/Lab02/images/get-data.png)\n\n2. Enter your Spark cluster's server name in the Server field. This will be [YOUR_CLUSTER_NAME].azurehdinsight.net.\n3. Select DirectQuery as the data connectivity mode, then click OK.\n\n![Get Data](https://raw.githubusercontent.com/ZoinerTejada/hdi-labs/master/Labs/Lab02/images/get-data-directquery.png)\n\n4. Enter your credentials you defined when you provisioned the cluster.\n5. After authenticating, continue to the next step and check the boxes next to the `weblogs`, `users`, and `products` tables, then click Load.\n\n![Get Data](https://raw.githubusercontent.com/ZoinerTejada/hdi-labs/master/Labs/Lab02/images/directquery.png)\n", "cell_type": "markdown", "metadata": {}}, {"source": "## Configure table relationships", "cell_type": "markdown", "metadata": {}}, {"source": "Before we can start combining columns from related tables for our charts, we first need to configure the table relationships.\n\nCreate the following relationships before continuing:\n\n| From: Table (Column) | To: Table (Column) |\n| -- | -- |\n| weblogs (ProductId) | products (ProductId) |\n| weblogs (UserId) | users (id) |", "cell_type": "markdown", "metadata": {}}, {"source": "## Create the charts", "cell_type": "markdown", "metadata": {}}, {"source": "Now that the tables are loaded using DirectQuery, you will see them listed on the right-hand side of the Power BI page, under the Fields heading. When you select fields from this list, a table visualization is automatically created. Use the visualization icons to use the selected data for new types of charts and other visualizations.\n\n> Power BI displays details of each chart item when you mouse over them. For instance, when you hover your mouse over the slices of the pie chart, Power BI will helpfully display the action name, count, and percentage of that action. This feature is available on all visualization types.", "cell_type": "markdown", "metadata": {}}, {"source": "### Create a Pie Chart visualization\n\nCreate a new Pie Chart visualization to display the three actions from the weblogs table, and their percentages. This will be very similar to the pie chart we created in Jupyter.\n\nThe result should look similar to this:\n\n![Pie Chart](https://raw.githubusercontent.com/ZoinerTejada/hdi-labs/master/Labs/Lab02/images/piechart.png)", "cell_type": "markdown", "metadata": {}}, {"source": "### Change the title of the Pie Chart\n\nPower BI makes a best guess on what the title of your visualizations should be. However, we can change the title to make the context of the visualizations make more sense.\n\nChange the title of the pie chart to \"User Actions\".", "cell_type": "markdown", "metadata": {}}, {"source": "### Add a Stacked Column Chart\n\nSimilar to the stacked bar charts we created with Matplotlib, we'll create a stacked column chart in Power BI to compare purchasing actions (Add to Cart, and Purchased) by gender.\n\nThe chart we create should look like the following, and be titled \"Purchasing actions by gender\":\n\n![Stacked Column Chart](https://raw.githubusercontent.com/ZoinerTejada/hdi-labs/master/Labs/Lab02/images/stacked-columnchart.png)", "cell_type": "markdown", "metadata": {}}, {"source": "### Add a Clustered Column Chart\n\nBecause the number of browsed actions are so high, we'll display those counts in their own chart. We can display the browsed count for males and females side-by-side using the clustered column chart visualization.\n\nThe chart we create should look like the following, and be titled \"Browsing counts by gender\":\n\n![Clustered Column Chart](https://raw.githubusercontent.com/ZoinerTejada/hdi-labs/master/Labs/Lab02/images/clustered-columnchart.png)", "cell_type": "markdown", "metadata": {}}, {"source": "### Add a Waterfall Chart\n\nThe sales department is interested in seeing the top 6 products sold at any time, including the how many of each product was sold, and the total amount of those six products combined.\n\nThe chart we create should look like the following, and be titled \"Top 6 products sold\":\n\n![Waterfall Chart](https://raw.githubusercontent.com/ZoinerTejada/hdi-labs/master/Labs/Lab02/images/waterfallchart.png)", "cell_type": "markdown", "metadata": {}}, {"source": "After you are done, your page should look similar to the following:\n\n![Completed page](https://raw.githubusercontent.com/ZoinerTejada/hdi-labs/master/Labs/Lab02/images/completed-report.png)", "cell_type": "markdown", "metadata": {}}, {"source": "## Conclusion", "cell_type": "markdown", "metadata": {}}, {"source": "In the lab, you have learned how to use Spark SQL (and PySpark) to quickly explore gigabytes of data, simplify understanding the data through visualization within Jupyter, and then create nice, interactive versions of those visuals within Power BI.\n\nSpecifically you:\n* Queried data stored in Hive tables.\n* Copied product data from a Spark SQL DataFrame into a new Hive table that can be accessed from Power BI.\n* Explored Jupyter's built-in visualizations, and used the more powerful Matplotlib charts to effectively explore the data.\n* Learned how to work with the Pandas DataFrames within the local context.\n* Set up a DirectQuery connection in Power BI to Spark.\n* Created visualizations in Power BI directly from the Spark data.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}, "celltoolbar": "Raw Cell Format"}}