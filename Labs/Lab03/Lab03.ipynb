{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Data Science using Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdventureWorks would like to add a snazzy product recommendations feature to their website and email marketing campaigns that, for every user in their system, can recommend the top 10 products they might be interested in purchasing.\n",
    "\n",
    "Adventureworks has provided you with the tables for users, products and weblogs that contains all of the data you need. You will train a recommendation model using Spark's built-in collaborative filtering alogrithm - [Alternating Least Squares (ALS)](http://spark.apache.org/docs/2.1.0/mllib-collaborative-filtering.html). Then you will use the model to pre-compute the user to product recommendation for every user and save this in a table. Then you will query from this table to quickly get the 10 product recommendations for a given user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing the Weblogs Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the modules and functions we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "from pyspark.mllib.recommendation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weblogs table we have tells us what actions a user took on any given product when using the website. A user can browse a product, add it to the cart or purchase it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT UserId,  ProductId, Action FROM weblogs limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training and test data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by selecting a significant subset of our data to use in training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = spark.sql(\"select * from weblogs where cleanedtransactiondate between '2016-03-01' and '2016-05-31'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by defining how we want to weigh the implicit rating described by the action field in the weblogs table. An implicit rating occurs here because a user is not explictly providing a rating (e.g., they never say \"I rate this product 4 out of 5 stars\". Instead we will infer their rating by virtue of their action. \n",
    "\n",
    "A product that is browsed gets 30 points, a product that is added to the cart gets 70 points and a product that is purchased gets 100 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ActionPoints = {\"Browsed\":30, \"Add To Cart\":70, \"Purchased\":100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a new RDD that contains the a tuple with only the data we are interested in plus the value of the action taken. So our ratings will include the UserId, the ProductId and the Points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratingsRdd = train.rdd.map(lambda s: [s.UserId, s.ProductId, ActionPoints[s.Action]])\n",
    "ratingsRdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a model using ALS, we should cache the RDD because algorithm will revist the dataset many times over during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratingsRdd.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building a model using ALS there are some settings referred to as hyperparameters that we need to use guide how the model gets trained. Typically you find the best values by iterating through a range of possible values and evaluating the predictive result. For simplicity, we will begin with the following settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank = 10\n",
    "numIterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train our data using the training data set and our hyperparameters. **Note that this will take about 12 minutes to complete.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Invoke the train function of the ALS object providing the ratingsRDD, rank and numIterations\n",
    "model = #TODO( , , )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you noticed, training a model takes some time. Fortunately, we don't have pay the training cost everytime we want to use the model. To allow us to re-use a trained model, we can save it to disk (in Azure Storage).\n",
    "\n",
    "First, let's make sure we have a clean models directory (in practice you an store the models anywhere you want, but we chose /models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "hdfs dfs -rm -r /models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to create a subfolder for our collaborative filtering model. We'll name the subfolder cfmodel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "hdfs dfs -mkdir /models\n",
    "hdfs dfs -mkdir /models/cfmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the folder structure in place, we need to invoke the save method on the model and indicate the path to the folder we created for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Invoke the save method on the model object, providing the SparkContext (sc) and the path in which to serialize the model.\n",
    "model.#TODO( , \"/models/cfmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let's confirm our model was saved succesfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "hdfs dfs -ls /models/cfmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's put our model to use. We'll begin by using the recommendProductsForUsers function provided by our model to recommend 100 products for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(model.recommendProductsForUsers.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: invoke the recommendProductsForUsers function of the model for 100 users.\n",
    "products_for_users = model.#TODO( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's uses those recommendations to create an RDD where each row contains the ProductId, UserId and the Rating of the match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_product_ratings = products_for_users.flatMap(lambda xs: [Row(UserId=x[0], ProductId=x[1], Rating=x[2]) for x in xs[1]])\n",
    "users_product_ratings.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's convert this RDD into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_product_ratings_df = users_product_ratings.toDF()\n",
    "user_product_ratings_df.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll register this DataFrame as a temporary view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_product_ratings_df.createOrReplaceTempView(\"UserProductRatings_View\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a temporary view for the products data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to load and parse the data from Azure Storage and present it using a temporary view called Products_View. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DefineProductsFields(inline):\n",
    "    l = inline.split(\",\")\n",
    "    return Row(ProductId=int(l[0]),ProductName=l[1],BasePrice=float(l[2]),CategoryId=l[3],Category=l[7],Department=l[8])\n",
    "\n",
    "products = sc.textFile(\"/retaildata/rawdata/ProductFile/part{*}\")\n",
    "\n",
    "products_RDD = products.map(lambda p:DefineProductsFields(p))\n",
    "products_RDD.take(5)\n",
    "products_DF = products_RDD.toDF()\n",
    "products_DF_with_price = products_DF.select(\n",
    "    products_DF.ProductId,\n",
    "    products_DF.ProductName,\n",
    "    products_DF.BasePrice.cast(\"decimal\").alias(\"Price\"),\n",
    "    products_DF.CategoryId,\n",
    "    products_DF.Category,\n",
    "    products_DF.Department)\n",
    "products_DF_with_price.createOrReplaceTempView(\"Products_View\")\n",
    "products_DF_with_price.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the top 10 recommended products for given user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our product data available as a view, we now have all of the data sources we need to start making recommendations: Products_View, the UserProductRatings_View and the Users table. We define a function that will get us the top 10 recommended products for a given user (by user ID) by querying our data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetRecommendedProductsForUser(UserId):\n",
    "    user_product_mapping = spark.sql(\"SELECT * FROM UserProductRatings_View WHERE UserId =\" + str(UserId))\n",
    "    recommended_products = user_product_mapping.join(\n",
    "        products_DF_with_price, user_product_mapping.ProductId == products_DF_with_price.ProductId\n",
    "    ).select(\n",
    "        products_DF_with_price.ProductName,\n",
    "        products_DF_with_price.Price,\n",
    "        products_DF_with_price.Category,\n",
    "        products_DF_with_price.Department,\n",
    "        user_product_mapping.Rating\n",
    "    )\n",
    "    print(\"Users Information:\")\n",
    "    users_data = spark.sql(\"SELECT FirstName, LastName, Gender, Age from users WHERE id =\" + str(UserId))\n",
    "    users_data.show(1)\n",
    "    print(\"Recommended Products:\")\n",
    "    recommended_products.orderBy('Rating',ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's invoke the above function for a sample user and examine what products our model suggests we recommend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GetRecommendedProductsForUser(UserId = 1336)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret these results. If you look at the Rating column, the values for this user range from 30.29 to 55.86, whereby the higher the rating, the more confident we are of the recommendation. \n",
    "\n",
    "So now we need to ask ourselves, do these recommendation make sense for our example customer Frederik Nielsen? Let's look at how we might answer this question in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by getting a sense for what items Frederik buys or strongly considers buying (by ading them to his cart). We can run the following query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select w.Action, p.Department, p.Category, count(*)\n",
    "from weblogs w \n",
    "join products p on w.ProductId = p.ProductId\n",
    "where UserId = 1336 and Action = \"Purchased\" or Action = \"Add To Cart\"\n",
    "group by w.Action, p.Department, p.Category\n",
    "order by w.Action desc, count(*) desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the output that the top two department\\categories for his purchases by the number of actions are Clothing\\Men and Clothing\\Sport Shoes. Our recommender certainly recommended those above. But what about the Appliance Department items it recommended?\n",
    "\n",
    "Again looking at the summary of Frederick's activities, we see that he frequently adds items to his cart that are in the Appliance\\Kitchen Applicance category. In fact this is the #2 most common category of good he adds to his shopping cart. So while the recommender missed out on suggesting Houseware\\Bedding (his #1 category of items added to the cart), these results are certainly reasonable for him."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you learned how to perform collaborative filtering on a fairly large dataset and in the process, helped AdventureWorks recommend products to its users based on their activity on the website."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark3",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
